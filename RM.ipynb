{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GzfMPvxERi0s0T-BbzvHbaHe9Vwg3nuB",
      "authorship_tag": "ABX9TyMCNaPr7xgqWh6uyXyxjmgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atrbyg24/gpt2-rlhf/blob/main/RM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reward Model Training**"
      ],
      "metadata": {
        "id": "_Fxz4BcCt3E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-mr4BFVttb0"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "hugging_face_token = userdata.get('hugging_face_read_token')\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "model_name = 'gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets"
      ],
      "metadata": {
        "id": "BgI-s0R3t80p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset_name = 'sst2'\n",
        "dataset = load_dataset(dataset_name)\n",
        "dataset"
      ],
      "metadata": {
        "id": "GX-N6IZ-t_XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_val = dataset['train'], dataset['validation']"
      ],
      "metadata": {
        "id": "szbMY_uFuIFY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REWARD_TOKEN_ID = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "BBLWd2o9uMZ8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    outputs = tokenizer(batch['sentence'])\n",
        "    outputs['score'] = [0] * len(outputs['input_ids'])\n",
        "    outputs['score_index'] = [0] * len(outputs['input_ids'])\n",
        "    for i in range(len(outputs['input_ids'])):\n",
        "        outputs['input_ids'][i].append(REWARD_TOKEN_ID)\n",
        "        outputs['attention_mask'][i].append(1)\n",
        "        outputs['score'][i] = float(batch['label'][i])\n",
        "        outputs['score_index'][i] = len(outputs['input_ids'][i]) - 1\n",
        "    return outputs\n",
        "\n",
        "map_kwargs = {\n",
        "    \"batched\": True,\n",
        "    \"batch_size\": 512,\n",
        "    \"remove_columns\": ['idx', 'sentence', 'label']\n",
        "}\n",
        "\n",
        "tokenized_dataset_train = ds_train.map(tokenize, **map_kwargs)\n",
        "tokenized_dataset_val = ds_val.map(tokenize, **map_kwargs)"
      ],
      "metadata": {
        "id": "JY0ycuWNuUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train.set_format('torch')\n",
        "tokenized_dataset_val.set_format('torch')"
      ],
      "metadata": {
        "id": "i2-uSnMI9Zkg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train = tokenized_dataset_train.filter(lambda x: len(x['input_ids']) > 6)\n",
        "tokenized_dataset_val = tokenized_dataset_val.filter(lambda x: len(x['input_ids']) > 6)"
      ],
      "metadata": {
        "id": "NkwyfKwn9kBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM with Reward Head**"
      ],
      "metadata": {
        "id": "zAAj3yl191R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "class RewardHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.reward = nn.Linear(self.hidden_size, 1)\n",
        "        self._post_init()\n",
        "\n",
        "    def _post_init(self):\n",
        "        nn.init.normal_(self.reward.weight, std=(1.0 / np.sqrt(self.hidden_size + 1)))\n",
        "        nn.init.zeros_(self.reward.bias)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        return self.reward(hidden_states)\n",
        "\n",
        "class GPT2RewardHead(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.llm = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "        self.reward_head = RewardHead(self.llm.config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        transformer_outputs = self.llm.forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "        last_hidden_state = transformer_outputs.hidden_states[-1]\n",
        "        reward = self.reward_head(last_hidden_state).squeeze(-1)\n",
        "        return torch.sigmoid(reward)"
      ],
      "metadata": {
        "id": "rGL73g-X9ucc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2RewardHead(model_name)"
      ],
      "metadata": {
        "id": "RW7UY2IB_JDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "dataloader_params = {\n",
        "    'batch_size': 64,\n",
        "    'shuffle': True,\n",
        "    'collate_fn': data_collator\n",
        "}\n",
        "train_dataloader = DataLoader(tokenized_dataset_train, **dataloader_params)\n",
        "val_dataloader = DataLoader(tokenized_dataset_val, **dataloader_params)"
      ],
      "metadata": {
        "id": "ak6wjuj-_ZFw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Config**"
      ],
      "metadata": {
        "id": "0NeWaso7_jKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.BCELoss()\n",
        "num_epochs = 1 # N+ Implementation Detail paper"
      ],
      "metadata": {
        "id": "WOt4BOYs_ilo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        inputs = batch.to(device)\n",
        "        model_inputs = {\n",
        "            'input_ids': inputs['input_ids'],\n",
        "            'attention_mask': inputs['attention_mask']\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            scores = model(**model_inputs)\n",
        "            batch_indices = torch.arange(scores.shape[0])\n",
        "            score = scores[batch_indices, inputs['score_index']]\n",
        "            target = inputs['score']\n",
        "            loss = criterion(score, target)\n",
        "        total_loss += loss.item()\n",
        "    print('validation loss:', total_loss / len(val_dataloader))"
      ],
      "metadata": {
        "id": "L_ENROxNArPw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "eFrvJcCqAKkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        inputs = batch.to(device)\n",
        "        model_inputs = {\n",
        "            'input_ids': inputs['input_ids'],\n",
        "            'attention_mask': inputs['attention_mask']\n",
        "        }\n",
        "        scores = model(**model_inputs)\n",
        "        batch_indices = torch.arange(scores.shape[0])\n",
        "        score = scores[batch_indices, inputs['score_index']]\n",
        "        target = inputs['score']\n",
        "        loss = criterion(score, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item())\n",
        "    validate()"
      ],
      "metadata": {
        "id": "XrAlXvMjAJuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pn8dU27Z4qzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/reward_model.pt')"
      ],
      "metadata": {
        "id": "vKtk9ew1A09q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate()"
      ],
      "metadata": {
        "id": "PGiFvQXpA2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "Hrf0HXisA4u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "for i, batch in enumerate(val_dataloader):\n",
        "    inputs = batch.to(device)\n",
        "    model_inputs = {\n",
        "        'input_ids': inputs['input_ids'],\n",
        "        'attention_mask': inputs['attention_mask']\n",
        "    }\n",
        "    with torch.no_grad():\n",
        "        scores = model(**model_inputs)\n",
        "        batch_indices = torch.arange(scores.shape[0])\n",
        "        score = scores[batch_indices, inputs['score_index']]\n",
        "        target = inputs['score']\n",
        "    predictions = (score > 0.5).int()\n",
        "\n",
        "    all_predictions.extend(predictions.cpu().numpy())\n",
        "    all_labels.extend(target.cpu().numpy())\n",
        "\n",
        "confusion_matrix(all_labels, all_predictions)\n"
      ],
      "metadata": {
        "id": "66fG7wnhA4fE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}